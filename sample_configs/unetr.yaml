---
patch_size: [16,16,16]
embedding_size: 768
number_of_blocks: 12
n_heads: 12
mlp_structure: [3072]
return_at: [3,6,9]
spatial_dimensions: 3
embed_method: "linear"
conv_type: "regular"
link_type: "residual"
upscale_type: "transpose"
norm_type: "instance"
interpolation: "bilinear"
padding: 1
dropout_rate: 0.1
dropout_param: 0
activation_fn: "leaky_relu"
n_channels: 1
depth: [16,32,64,128]
kernel_sizes: [3,3,3,3]
learning_rate: 0.005
batch_size: 4
weight_decay: 0.0005
loss_fn: "focal"
