---
patch_size: [16,16,8]
embedding_size: 512
number_of_blocks: 8
n_heads: 8
mlp_structure: [1024]
return_at: [2, 4, 6]
spatial_dimensions: 3
embed_method: "linear"
conv_type: "regular"
link_type: "residual"
upscale_type: "transpose"
norm_type: "instance"
interpolation: "bilinear"
padding: 1
dropout_rate: 0.1
dropout_param: 0
activation_fn: "leaky_relu"
n_channels: 1
depth: [16,32,64,128]
kernel_sizes: [3,3,3,3]
learning_rate: 0.005
batch_size: 4
weight_decay: 0.0005
loss_fn: 
  "dice":
    eps: 1.0e-6
    smooth: 1.0e-5
  "focal":
    gamma: 0.0
    eps: 1.0e-6
